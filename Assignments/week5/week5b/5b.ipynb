{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MMWp3bQP-bhU"
   },
   "source": [
    "# Lab 5 - Classification :  k-NN and Naive Bayes (using sklearn libraries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use **\"Pima Indians Diabetes Dataset from UCI Machine Learning Repository\"** for this question.It is a binary class dataset. Split the dataset into train(80%), validation(10%) and test sets(10%).\n",
    "\n",
    "Run k-Nearest neighbours for different k values. Choose your own subset of k (atleast 10) and choose the best value of k from this subset. In solving real-world problems, the values of k are chosen based on experience and hence it is a tunable hyperparameter. Select the k, using validation set, which returns the best accuracy score. Report accuracy score by performing k-NN on the test dataset using the chosen k value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "from sklearn.datasets import load_digits\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB,BernoulliNB\n",
    "from sklearn.metrics import f1_score,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('diabetes.csv')\n",
    "data = data.to_numpy()\n",
    "X = data[:,0:-1]\n",
    "y = data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "X_train, X_, y_train, y_ = train_test_split(X, y, test_size= 0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_,y_,test_size = 0.5,random_state=42)\n",
    "y_val = y_val[:,np.newaxis]\n",
    "y_test = y_test[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 117.14it/s]\n"
     ]
    }
   ],
   "source": [
    "K_list = [3,7,11,15,19,23,27,31,35,39]\n",
    "score_list = []\n",
    "for k in tqdm(range(len(K_list))):\n",
    "    neigh = KNeighborsClassifier(n_neighbors=K_list[k])\n",
    "    neigh.fit(X_train, y_train)\n",
    "    y_pred = neigh.predict(X_val)\n",
    "    y_pred = y_pred[:,np.newaxis]\n",
    "    score = float(sum(y_pred == y_val))/ float(len(y_val))\n",
    "    score_list.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val accuracy: 72.72727272727273\n",
      "Best K: 11\n"
     ]
    }
   ],
   "source": [
    "print(\"Best val accuracy:\",np.max(score)*100)\n",
    "print(\"Best K:\",K_list[np.argmax(score_list)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy for K=11: 0.7012987012987013\n"
     ]
    }
   ],
   "source": [
    "###Test set accuracy\n",
    "neigh = KNeighborsClassifier(n_neighbors=11)\n",
    "neigh.fit(X_train, y_train)\n",
    "y_pred = neigh.predict(X_test)\n",
    "y_pred = y_pred[:,np.newaxis]\n",
    "score = float(sum(y_pred == y_test))/ float(len(y_test))\n",
    "print(\"Test set accuracy for K=11:\",score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With increasing k, score increase, but dips after reaching a maxima "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use **\"Optical recognition of handwritten digits dataset\"** for this question. ** Download dataset from sklearn**. The dataset has 10 classes and 64 attributes (8x8 images). Visualise images from the dataset. Perform a train test split in the ratio 4:1. \n",
    "\n",
    "Naive Bayes - perform multiclass classification to classify the dataset into one of the ten classes. Experiment with the priors (Gaussian and Bernoulli) and report the best prior. Report the accuracies in terms of F1 scores and the confusion matrix (use sklearn functions for this too).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f08e17d45b0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code here\n",
    "np.random.seed(10)\n",
    "digits = load_digits()\n",
    "X = np.resize(digits.images,(len(digits.images),64))\n",
    "Y = digits.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "plt.gray()\n",
    "plt.title(\"Image of {}\".format(digits.target[5]))\n",
    "plt.imshow(digits.images[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for GaussianNB()\n",
      "0.8489770318561581\n",
      "Confusion matrix for GaussianNB()\n",
      "[[31  0  0  0  0  1  0  1  0  0]\n",
      " [ 0 24  0  0  0  0  0  0  3  1]\n",
      " [ 0  2 20  0  0  0  1  0 10  0]\n",
      " [ 0  0  1 29  0  1  0  0  3  0]\n",
      " [ 0  0  0  0 38  0  1  7  0  0]\n",
      " [ 0  0  0  1  0 44  1  1  0  0]\n",
      " [ 0  0  0  0  1  0 34  0  0  0]\n",
      " [ 0  0  0  0  0  1  0 33  0  0]\n",
      " [ 0  2  0  0  0  0  0  2 26  0]\n",
      " [ 0  1  1  2  0  2  0  4  4 26]]\n",
      "F1 score for BernoulliNB()\n",
      "0.8624817234502353\n",
      "Confusion matrix for BernoulliNB()\n",
      "[[31  0  0  0  2  0  0  0  0  0]\n",
      " [ 0 18  4  0  0  0  0  0  4  2]\n",
      " [ 0  1 29  2  0  0  0  0  1  0]\n",
      " [ 0  0  2 29  0  0  0  0  2  1]\n",
      " [ 0  0  0  0 45  0  0  1  0  0]\n",
      " [ 1  0  0  2  0 36  2  0  0  6]\n",
      " [ 0  0  0  0  1  0 34  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 34  0  0]\n",
      " [ 0  3  1  0  0  0  0  0 24  2]\n",
      " [ 0  1  0  1  2  1  0  3  1 31]]\n"
     ]
    }
   ],
   "source": [
    "prior_list = [GaussianNB(),BernoulliNB()]\n",
    "\n",
    "for prior in prior_list:\n",
    "    #Prior\n",
    "    model = prior.fit(X_train,y_train)\n",
    "    #testing accuracies\n",
    "    y_pred = model.predict(X_test)\n",
    "    #F1 score\n",
    "    f1 = f1_score(y_test,y_pred,average=\"weighted\")\n",
    "    print(\"F1 score for {}\\n{}\".format(str(prior),f1))\n",
    "    #Confusion matrix\n",
    "    con_mat = confusion_matrix(y_test,y_pred)\n",
    "    print(\"Confusion matrix for {}\\n{}\".format(str(prior),con_mat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the F1 scores and confusion matrix we can say that BernoulliNB is better in this case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oli7OP9XN4ZF"
   },
   "source": [
    "Summarize your findings and results here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab5_DataAnalytics.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
